{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classifier - From Siraj's Udacity Lecture\n",
    "\n",
    "Here is my attempt at recreating the image classification model shown in Siraj's video lecture through the \"Foundation in Deep Learning\" course on Udacity. The original tutorial (that Siraj borrowed from) can be found here: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "The tutorial uses Keras to build the image classifier from just a few hundred pictures in each class. \n",
    "\n",
    "Keras is essentially a high-level neural netwroks API, written in python. It is capable of running on top of TensorFlow (or Theano). The goal of developing this API was to focus on enabling fast experimentation (which is awesome). \n",
    "Keras provides access to a deep learning library that:\n",
    "* Allows for easy and fast prototyping\n",
    "* Supports both convolutional networks and recurrent network, as the combination thereof\n",
    "* Runs on CPU and GPU\n",
    "\n",
    "(More about this on [Keras Documentation](http://keras.io))\n",
    "\n",
    "In this notebook I attempt to understand the following key options:\n",
    "* training a small network from scratch\n",
    "* using the bottleneck features on pre trained network\n",
    "* fine tuning the top laters of pre trained network\n",
    "\n",
    "And this is accomplished by using the following features from Keras:\n",
    "* fit_generator for training Keras a model using Python data generators\n",
    "* ImageDataGEnerator for real-time data augmentation\n",
    "* layer freezing and model fine tuning\n",
    "\n",
    "\n",
    "### Data\n",
    "\n",
    "The data used here is available [here](https://www.kaggle.com/c/dogs-vs-cats/data)\n",
    "\n",
    "The recommended folder structure is as follows:\n",
    "\n",
    "```python\n",
    "data/\n",
    "    train/\n",
    "        dogs/ ### 1024 pictures\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/ ### 1024 pictures\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/ ### 416 pictures\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/ ### 416 pictures\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "Note : for this example we only consider 2x1000 training images and 2x400 testing images among the 2x12500 available.\n",
    "\n",
    "Note: The kaggle website linked above uses about 25,000 images, I use only  about 1500 images for this model and these can be dounf in the git repo from the tutorial linked above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Users/vivek/anaconda/envs/tensorflow/lib/python3.5/site-packages\n",
      "Requirement already satisfied: olefile in /Users/vivek/anaconda/envs/tensorflow/lib/python3.5/site-packages (from pillow)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##TensorFlow is the backend for Keras in this notebook\n",
    "!pip install pillow\n",
    "!KERAS_BACKEND=tensorflow python -c \"from keras import backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note: To ensure the above code works, make sure you go into your terminal (Im using mac) and type up the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda create -n tensorflow python=3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source activate tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda install pandas matplotlib jupyter notebook scipy scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This essentially ensures all the dependancies have been installed and taken care of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dimensions of the images\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = '/Users/vivek/data/train'\n",
    "validation_data_dir = '/Users/vivek/data/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2048 images belonging to 2 classes.\n",
      "Found 2048 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#used to rescale the pixel values from [0,255] to [0,1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#automatically retrive images and their classes for training and validation\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width,img_height),\n",
    "        batch_size = 16,\n",
    "        class_mode = 'binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width,img_height),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Small Conv Net\n",
    "\n",
    "### Model Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivek/anaconda/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(150, 150,...)`\n",
      "  del sys.path[0]\n",
      "/Users/vivek/anaconda/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "/Users/vivek/anaconda/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    }
   ],
   "source": [
    "#Building the Model\n",
    "\n",
    "#Sequential function allows us to build a linear stack of layers\n",
    "#so we treat each layer as an object that feeds data to the next one.\n",
    "\n",
    "#The alternative is a graph model (not using here), and it would allow\n",
    "#multiple seperate inputs and outputs. This is a simpler example though\n",
    "model = Sequential()\n",
    "\n",
    "#Now we add out first layer, the convolutional layer\n",
    "#The first layer of a CNN is always a convolutional layer\n",
    "#The input is a 32x32x3 array of pixel values. 3 refers to RGB\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n",
    "\n",
    "\n",
    "#Now we pass this feature map through an activtion layer, ReLU\n",
    "#ReLU is a non linear operation that replaces all the negative pixel \n",
    "#values in the feature map with zero. THis layer increases the non linear\n",
    "#properties of our model, meaning our neural net will be able to learn \n",
    "#more complex functions\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#We now initalize our max pooling layer. This reduces the dimensionality\n",
    "#of each feature map but retains the most imp information\n",
    "#Reduces the computational complexity of the network too \n",
    "#We use Max pooling here which takes the max value from a feature of size\n",
    "#we define at each slide\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#A classis CNN looks like so:\n",
    "#Input->Cov->ReLU->Pool->Conv->ReLU->Pool->FullyConnected\n",
    "\n",
    "#Following that we have the next layers like so:\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "#A technique used to prevent overfitting, the point when a model isn't\n",
    "#able to predict labels for novel data is Dropout. A dropout layer\n",
    "#drops out a random set of activations in that layer by setting them to zero\n",
    "#as data flows through it\n",
    "\n",
    "#we first flatten the feature map into 1D to prepare for dropout\n",
    "model.add(Flatten())\n",
    "\n",
    "#now initalize a fully connected layer with a dense function and \n",
    "#apply ReLU to it\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#After dropout, we initialize one more fully connected layer\n",
    "#this will output an n dimensional vector, where n is the number of classes\n",
    "#we have, so here we will have 2 - Dogs and Cats\n",
    "#Applying sigmoid to it, will convert the data into probabilities\n",
    "#for each class \n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "An important question at this stage is how does the network learn? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to this is that we'll want to minimize our loss function, which is measures the difference between the target output and the expected output. To accomplish this we take the derivative of the loss, with respect to the weights in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The learning process can then be figured using the complie method\n",
    "#where our loss is defined as binary crossentropy(the preferred\n",
    "#loss function for binary problems - Cat/Dog type)\n",
    "#We will then use or optimizer- rmsprop, which will perform the\n",
    "#gradient descent. And finally a list of metrics, set to accuracy\n",
    "#as this is a classification problem.\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we wrte out our fit function to train the model, giving it parameters for the training and validation data and the number of epochs to run for each. We also save our weights, so we can use our trained model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 10\n",
    "nb_train_samples = 2048\n",
    "nb_validation_samples = 832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivek/anaconda/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., steps_per_epoch=128, validation_steps=832, validation_data=<keras.pre..., epochs=10)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "128/128 [==============================] - 531s - loss: 0.1321 - acc: 0.9561 - val_loss: 0.0468 - val_acc: 0.9871\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 556s - loss: 0.1166 - acc: 0.9595 - val_loss: 0.0181 - val_acc: 0.9961\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 575s - loss: 0.0947 - acc: 0.9727 - val_loss: 0.0483 - val_acc: 0.9825\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 550s - loss: 0.1117 - acc: 0.9624 - val_loss: 0.0646 - val_acc: 0.9837\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 497s - loss: 0.1337 - acc: 0.9541 - val_loss: 0.0309 - val_acc: 0.9956\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 495s - loss: 0.1207 - acc: 0.9619 - val_loss: 0.0197 - val_acc: 0.9941\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 502s - loss: 0.1194 - acc: 0.9663 - val_loss: 0.0386 - val_acc: 0.9899\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 530s - loss: 0.1358 - acc: 0.9683 - val_loss: 0.0212 - val_acc: 0.9941\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 563s - loss: 0.1202 - acc: 0.9624 - val_loss: 0.0188 - val_acc: 0.9947\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 537s - loss: 0.1327 - acc: 0.9629 - val_loss: 0.0158 - val_acc: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1220fe978>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next I save the weights so I can load them and use them later if I want\n",
    "#Note: This will require for you to import h5py\n",
    "#model.save_weights('models/basic_cnn_20_epochs.h5')\n",
    "\n",
    "#This can be loaded as follows\n",
    "##model.load_weights('models_trained/basic_cnn_20_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of the number of epochs, I first tested it with 1 epoch and then ran it through 10. Ideally, the more epochs you run through , the more accuracy you will get. However I am currently running this on a macbook air and running 30 epochs would take forever. Hence, the brevity.\n",
    "\n",
    "My value accuracy is still pretty strong sitting at about 99.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing loss and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01594636875880549, 0.99515474759615385]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(validation_generator, nb_validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see we have minimal loss here and a very high accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
